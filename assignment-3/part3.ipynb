{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPnZARZqQXkh"
      },
      "outputs": [],
      "source": [
        "#importing the dataset and libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQo5hnA1QXkk",
        "outputId": "7cf4077e-6848-47fb-b6aa-31892cb2f296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device found: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "#Checking for GPU availability\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU device found: {}'.format(tf.test.gpu_device_name()))\n",
        "    device = '/device:GPU:0'\n",
        "else:\n",
        "    print('No GPU device found. Using CPU.')\n",
        "    device = '/device:CPU:0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff1q0JPIQXkl"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train),(x_test, y_test) = mnist.load_data() #Splitting data into test and train  \n",
        "\n",
        "x_train = x_train.reshape(-1, 784) / 255.0              #Flattening the (28X28) data to (784x1)\n",
        "x_test = x_test.reshape(-1, 784) / 255.0                #and normalizing the greyscale intensities\n",
        "\n",
        "\n",
        "x_validation, x_train = x_train[:5000], x_train[5000:]  #5000 data points for validation\n",
        "y_validation, y_train = y_train[:5000], y_train[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1vB5bxwQXkl",
        "outputId": "e1ca1435-04cd-4f36-d190-a517f846b8d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((55000, 784), (10000, 784), (55000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl9CB0KyQXkm"
      },
      "outputs": [],
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_validation = tf.keras.utils.to_categorical(y_validation)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_validation.shape, x_test.shape, y_train.shape, y_validation.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-V_iKOwlSw7",
        "outputId": "e00e7d18-df32-4b6d-d5f2-4fed60429417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((55000, 784), (5000, 784), (10000, 784), (55000, 10), (5000, 10), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhUxyGLAQXkm"
      },
      "outputs": [],
      "source": [
        "#Neural Network with 3 layers, relu as activation for hidden layers\n",
        "# with softmax as activation for the output layer\n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-C6K0_XQXkm"
      },
      "outputs": [],
      "source": [
        "#Compiling the model with Adam Optimizer with categorical cross entropy as the loss function\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7ooEy6wQXkn"
      },
      "outputs": [],
      "source": [
        "#Setting batch size = 128 and epochs to 250\n",
        "batch_size = 128\n",
        "epochs = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUVTyiQcQXkn",
        "outputId": "552860c0-edde-41b3-d1fb-061399965363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250 - Loss: 0.1271 - Error: 0.0398\n",
            "Epoch 2/250 - Loss: 0.1121 - Error: 0.0358\n",
            "Epoch 3/250 - Loss: 0.1047 - Error: 0.0324\n",
            "Epoch 4/250 - Loss: 0.0885 - Error: 0.0266\n",
            "Epoch 5/250 - Loss: 0.0954 - Error: 0.0244\n",
            "Epoch 6/250 - Loss: 0.1207 - Error: 0.0324\n",
            "Epoch 7/250 - Loss: 0.0855 - Error: 0.0212\n",
            "Epoch 8/250 - Loss: 0.0844 - Error: 0.0210\n",
            "Epoch 9/250 - Loss: 0.0972 - Error: 0.0202\n",
            "Epoch 10/250 - Loss: 0.0985 - Error: 0.0210\n",
            "Epoch 11/250 - Loss: 0.0892 - Error: 0.0188\n",
            "Epoch 12/250 - Loss: 0.0855 - Error: 0.0194\n",
            "Epoch 13/250 - Loss: 0.1082 - Error: 0.0254\n",
            "Epoch 14/250 - Loss: 0.0929 - Error: 0.0210\n",
            "Epoch 15/250 - Loss: 0.1037 - Error: 0.0216\n",
            "Epoch 16/250 - Loss: 0.1060 - Error: 0.0220\n",
            "Epoch 17/250 - Loss: 0.0811 - Error: 0.0178\n",
            "Epoch 18/250 - Loss: 0.1030 - Error: 0.0194\n",
            "Epoch 19/250 - Loss: 0.1146 - Error: 0.0202\n",
            "Epoch 20/250 - Loss: 0.1180 - Error: 0.0190\n",
            "Epoch 21/250 - Loss: 0.1154 - Error: 0.0182\n",
            "Epoch 22/250 - Loss: 0.1149 - Error: 0.0168\n",
            "Epoch 23/250 - Loss: 0.1369 - Error: 0.0226\n",
            "Epoch 24/250 - Loss: 0.1372 - Error: 0.0194\n",
            "Epoch 25/250 - Loss: 0.1223 - Error: 0.0182\n",
            "Epoch 26/250 - Loss: 0.1124 - Error: 0.0172\n",
            "Epoch 27/250 - Loss: 0.1212 - Error: 0.0190\n",
            "Epoch 28/250 - Loss: 0.1398 - Error: 0.0180\n",
            "Epoch 29/250 - Loss: 0.1195 - Error: 0.0178\n",
            "Epoch 30/250 - Loss: 0.1180 - Error: 0.0170\n",
            "Epoch 31/250 - Loss: 0.1154 - Error: 0.0162\n",
            "Epoch 32/250 - Loss: 0.1375 - Error: 0.0196\n",
            "Epoch 33/250 - Loss: 0.1263 - Error: 0.0176\n",
            "Epoch 34/250 - Loss: 0.1132 - Error: 0.0158\n",
            "Epoch 35/250 - Loss: 0.1297 - Error: 0.0178\n",
            "Epoch 36/250 - Loss: 0.1437 - Error: 0.0172\n",
            "Epoch 37/250 - Loss: 0.1226 - Error: 0.0164\n",
            "Epoch 38/250 - Loss: 0.1165 - Error: 0.0154\n",
            "Epoch 39/250 - Loss: 0.1341 - Error: 0.0178\n",
            "Epoch 40/250 - Loss: 0.1414 - Error: 0.0172\n",
            "Epoch 41/250 - Loss: 0.1182 - Error: 0.0148\n",
            "Epoch 42/250 - Loss: 0.1548 - Error: 0.0220\n",
            "Epoch 43/250 - Loss: 0.1176 - Error: 0.0166\n",
            "Epoch 44/250 - Loss: 0.1204 - Error: 0.0162\n",
            "Epoch 45/250 - Loss: 0.1636 - Error: 0.0214\n",
            "Epoch 46/250 - Loss: 0.1391 - Error: 0.0158\n",
            "Epoch 47/250 - Loss: 0.1394 - Error: 0.0152\n",
            "Epoch 48/250 - Loss: 0.1361 - Error: 0.0186\n",
            "Epoch 49/250 - Loss: 0.1138 - Error: 0.0130\n",
            "Epoch 50/250 - Loss: 0.1220 - Error: 0.0148\n",
            "Epoch 51/250 - Loss: 0.1517 - Error: 0.0176\n",
            "Epoch 52/250 - Loss: 0.1276 - Error: 0.0164\n",
            "Epoch 53/250 - Loss: 0.1376 - Error: 0.0150\n",
            "Epoch 54/250 - Loss: 0.1229 - Error: 0.0150\n",
            "Epoch 55/250 - Loss: 0.1454 - Error: 0.0158\n",
            "Epoch 56/250 - Loss: 0.1246 - Error: 0.0144\n",
            "Epoch 57/250 - Loss: 0.1573 - Error: 0.0184\n",
            "Epoch 58/250 - Loss: 0.1406 - Error: 0.0162\n",
            "Epoch 59/250 - Loss: 0.1276 - Error: 0.0150\n",
            "Epoch 60/250 - Loss: 0.1234 - Error: 0.0144\n",
            "Epoch 61/250 - Loss: 0.1270 - Error: 0.0136\n",
            "Epoch 62/250 - Loss: 0.1626 - Error: 0.0146\n",
            "Epoch 63/250 - Loss: 0.1639 - Error: 0.0158\n",
            "Epoch 64/250 - Loss: 0.1370 - Error: 0.0146\n",
            "Epoch 65/250 - Loss: 0.2006 - Error: 0.0196\n",
            "Epoch 66/250 - Loss: 0.1555 - Error: 0.0178\n",
            "Epoch 67/250 - Loss: 0.1724 - Error: 0.0170\n",
            "Epoch 68/250 - Loss: 0.1501 - Error: 0.0172\n",
            "Epoch 69/250 - Loss: 0.1707 - Error: 0.0162\n",
            "Epoch 70/250 - Loss: 0.1867 - Error: 0.0172\n",
            "Epoch 71/250 - Loss: 0.1744 - Error: 0.0186\n",
            "Epoch 72/250 - Loss: 0.1540 - Error: 0.0154\n",
            "Epoch 73/250 - Loss: 0.1429 - Error: 0.0148\n",
            "Epoch 74/250 - Loss: 0.1468 - Error: 0.0154\n",
            "Epoch 75/250 - Loss: 0.2111 - Error: 0.0212\n",
            "Epoch 76/250 - Loss: 0.1860 - Error: 0.0162\n",
            "Epoch 77/250 - Loss: 0.1742 - Error: 0.0172\n",
            "Epoch 78/250 - Loss: 0.1647 - Error: 0.0164\n",
            "Epoch 79/250 - Loss: 0.1440 - Error: 0.0136\n",
            "Epoch 80/250 - Loss: 0.1412 - Error: 0.0142\n",
            "Epoch 81/250 - Loss: 0.1399 - Error: 0.0136\n",
            "Epoch 82/250 - Loss: 0.1396 - Error: 0.0132\n",
            "Epoch 83/250 - Loss: 0.1395 - Error: 0.0130\n",
            "Epoch 84/250 - Loss: 0.1394 - Error: 0.0130\n",
            "Epoch 85/250 - Loss: 0.1394 - Error: 0.0130\n",
            "Epoch 86/250 - Loss: 0.1394 - Error: 0.0132\n",
            "Epoch 87/250 - Loss: 0.1395 - Error: 0.0132\n",
            "Epoch 88/250 - Loss: 0.1397 - Error: 0.0132\n",
            "Epoch 89/250 - Loss: 0.1398 - Error: 0.0130\n",
            "Epoch 90/250 - Loss: 0.1400 - Error: 0.0130\n",
            "Epoch 91/250 - Loss: 0.1403 - Error: 0.0130\n",
            "Epoch 92/250 - Loss: 0.1406 - Error: 0.0130\n",
            "Epoch 93/250 - Loss: 0.1409 - Error: 0.0130\n",
            "Epoch 94/250 - Loss: 0.1413 - Error: 0.0130\n",
            "Epoch 95/250 - Loss: 0.1417 - Error: 0.0126\n",
            "Epoch 96/250 - Loss: 0.1421 - Error: 0.0126\n",
            "Epoch 97/250 - Loss: 0.1426 - Error: 0.0130\n",
            "Epoch 98/250 - Loss: 0.1431 - Error: 0.0130\n",
            "Epoch 99/250 - Loss: 0.1436 - Error: 0.0130\n",
            "Epoch 100/250 - Loss: 0.1442 - Error: 0.0130\n",
            "Epoch 101/250 - Loss: 0.1448 - Error: 0.0130\n",
            "Epoch 102/250 - Loss: 0.1455 - Error: 0.0130\n",
            "Epoch 103/250 - Loss: 0.1462 - Error: 0.0130\n",
            "Epoch 104/250 - Loss: 0.1469 - Error: 0.0128\n",
            "Epoch 105/250 - Loss: 0.1476 - Error: 0.0130\n",
            "Epoch 106/250 - Loss: 0.1484 - Error: 0.0132\n",
            "Epoch 107/250 - Loss: 0.1492 - Error: 0.0132\n",
            "Epoch 108/250 - Loss: 0.1500 - Error: 0.0134\n",
            "Epoch 109/250 - Loss: 0.1508 - Error: 0.0134\n",
            "Epoch 110/250 - Loss: 0.1516 - Error: 0.0132\n",
            "Epoch 111/250 - Loss: 0.1525 - Error: 0.0132\n",
            "Epoch 112/250 - Loss: 0.1533 - Error: 0.0132\n",
            "Epoch 113/250 - Loss: 0.1542 - Error: 0.0132\n",
            "Epoch 114/250 - Loss: 0.1550 - Error: 0.0132\n",
            "Epoch 115/250 - Loss: 0.1559 - Error: 0.0132\n",
            "Epoch 116/250 - Loss: 0.1567 - Error: 0.0132\n",
            "Epoch 117/250 - Loss: 0.1575 - Error: 0.0134\n",
            "Epoch 118/250 - Loss: 0.1582 - Error: 0.0132\n",
            "Epoch 119/250 - Loss: 0.1590 - Error: 0.0132\n",
            "Epoch 120/250 - Loss: 0.1597 - Error: 0.0132\n",
            "Epoch 121/250 - Loss: 0.1605 - Error: 0.0132\n",
            "Epoch 122/250 - Loss: 0.1611 - Error: 0.0132\n",
            "Epoch 123/250 - Loss: 0.1618 - Error: 0.0132\n",
            "Epoch 124/250 - Loss: 0.1624 - Error: 0.0130\n",
            "Epoch 125/250 - Loss: 0.1631 - Error: 0.0130\n",
            "Epoch 126/250 - Loss: 0.1637 - Error: 0.0130\n",
            "Epoch 127/250 - Loss: 0.1642 - Error: 0.0132\n",
            "Epoch 128/250 - Loss: 0.1647 - Error: 0.0132\n",
            "Epoch 129/250 - Loss: 0.1651 - Error: 0.0132\n",
            "Epoch 130/250 - Loss: 0.1656 - Error: 0.0132\n",
            "Epoch 131/250 - Loss: 0.1661 - Error: 0.0132\n",
            "Epoch 132/250 - Loss: 0.1665 - Error: 0.0132\n",
            "Epoch 133/250 - Loss: 0.1668 - Error: 0.0132\n",
            "Epoch 134/250 - Loss: 0.1671 - Error: 0.0132\n",
            "Epoch 135/250 - Loss: 0.1674 - Error: 0.0132\n",
            "Epoch 136/250 - Loss: 0.1677 - Error: 0.0132\n",
            "Epoch 137/250 - Loss: 0.1679 - Error: 0.0132\n",
            "Epoch 138/250 - Loss: 0.1682 - Error: 0.0132\n",
            "Epoch 139/250 - Loss: 0.1684 - Error: 0.0132\n",
            "Epoch 140/250 - Loss: 0.1685 - Error: 0.0136\n",
            "Epoch 141/250 - Loss: 0.1686 - Error: 0.0134\n",
            "Epoch 142/250 - Loss: 0.1687 - Error: 0.0134\n",
            "Epoch 143/250 - Loss: 0.1689 - Error: 0.0134\n",
            "Epoch 144/250 - Loss: 0.1690 - Error: 0.0134\n",
            "Epoch 145/250 - Loss: 0.1690 - Error: 0.0134\n",
            "Epoch 146/250 - Loss: 0.1691 - Error: 0.0134\n",
            "Epoch 147/250 - Loss: 0.1692 - Error: 0.0134\n",
            "Epoch 148/250 - Loss: 0.1693 - Error: 0.0134\n",
            "Epoch 149/250 - Loss: 0.1694 - Error: 0.0134\n",
            "Epoch 150/250 - Loss: 0.1694 - Error: 0.0134\n",
            "Epoch 151/250 - Loss: 0.1695 - Error: 0.0136\n",
            "Epoch 152/250 - Loss: 0.1696 - Error: 0.0136\n",
            "Epoch 153/250 - Loss: 0.1697 - Error: 0.0136\n",
            "Epoch 154/250 - Loss: 0.1697 - Error: 0.0136\n",
            "Epoch 155/250 - Loss: 0.1698 - Error: 0.0136\n",
            "Epoch 156/250 - Loss: 0.1699 - Error: 0.0136\n",
            "Epoch 157/250 - Loss: 0.1699 - Error: 0.0136\n",
            "Epoch 158/250 - Loss: 0.1699 - Error: 0.0136\n",
            "Epoch 159/250 - Loss: 0.1700 - Error: 0.0136\n",
            "Epoch 160/250 - Loss: 0.1700 - Error: 0.0136\n",
            "Epoch 161/250 - Loss: 0.1700 - Error: 0.0136\n",
            "Epoch 162/250 - Loss: 0.1700 - Error: 0.0136\n",
            "Epoch 163/250 - Loss: 0.1700 - Error: 0.0136\n",
            "Epoch 164/250 - Loss: 0.1701 - Error: 0.0136\n",
            "Epoch 165/250 - Loss: 0.1701 - Error: 0.0136\n",
            "Epoch 166/250 - Loss: 0.1701 - Error: 0.0134\n",
            "Epoch 167/250 - Loss: 0.1701 - Error: 0.0134\n",
            "Epoch 168/250 - Loss: 0.1701 - Error: 0.0134\n",
            "Epoch 169/250 - Loss: 0.1701 - Error: 0.0134\n",
            "Epoch 170/250 - Loss: 0.1701 - Error: 0.0134\n",
            "Epoch 171/250 - Loss: 0.1701 - Error: 0.0134\n",
            "Epoch 172/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 173/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 174/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 175/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 176/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 177/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 178/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 179/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 180/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 181/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 182/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 183/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 184/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 185/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 186/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 187/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 188/250 - Loss: 0.1700 - Error: 0.0134\n",
            "Epoch 189/250 - Loss: 0.1699 - Error: 0.0134\n",
            "Epoch 190/250 - Loss: 0.1699 - Error: 0.0134\n",
            "Epoch 191/250 - Loss: 0.1699 - Error: 0.0134\n",
            "Epoch 192/250 - Loss: 0.1699 - Error: 0.0134\n",
            "Epoch 193/250 - Loss: 0.1699 - Error: 0.0134\n",
            "Epoch 194/250 - Loss: 0.1699 - Error: 0.0134\n",
            "Epoch 195/250 - Loss: 0.1699 - Error: 0.0134\n",
            "Epoch 196/250 - Loss: 0.1698 - Error: 0.0134\n",
            "Epoch 197/250 - Loss: 0.1698 - Error: 0.0134\n",
            "Epoch 198/250 - Loss: 0.1698 - Error: 0.0134\n",
            "Epoch 199/250 - Loss: 0.1698 - Error: 0.0134\n",
            "Epoch 200/250 - Loss: 0.1698 - Error: 0.0134\n",
            "Epoch 201/250 - Loss: 0.1698 - Error: 0.0134\n",
            "Epoch 202/250 - Loss: 0.1698 - Error: 0.0130\n",
            "Epoch 203/250 - Loss: 0.1698 - Error: 0.0130\n",
            "Epoch 204/250 - Loss: 0.1698 - Error: 0.0130\n",
            "Epoch 205/250 - Loss: 0.1698 - Error: 0.0130\n",
            "Epoch 206/250 - Loss: 0.1698 - Error: 0.0130\n",
            "Epoch 207/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 208/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 209/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 210/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 211/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 212/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 213/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 214/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 215/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 216/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 217/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 218/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 219/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 220/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 221/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 222/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 223/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 224/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 225/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 226/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 227/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 228/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 229/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 230/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 231/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 232/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 233/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 234/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 235/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 236/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 237/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 238/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 239/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 240/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 241/250 - Loss: 0.1697 - Error: 0.0130\n",
            "Epoch 242/250 - Loss: 0.1696 - Error: 0.0130\n",
            "Epoch 243/250 - Loss: 0.1696 - Error: 0.0130\n",
            "Epoch 244/250 - Loss: 0.1696 - Error: 0.0130\n",
            "Epoch 245/250 - Loss: 0.1696 - Error: 0.0130\n",
            "Epoch 246/250 - Loss: 0.1696 - Error: 0.0130\n",
            "Epoch 247/250 - Loss: 0.1696 - Error: 0.0130\n",
            "Epoch 248/250 - Loss: 0.1696 - Error: 0.0130\n",
            "Epoch 249/250 - Loss: 0.1696 - Error: 0.0130\n",
            "Epoch 250/250 - Loss: 0.1696 - Error: 0.0130\n"
          ]
        }
      ],
      "source": [
        "with tf.device(device):\n",
        "    \n",
        "    loss_values = []\n",
        "    error_values = []\n",
        "\n",
        "    #each iteration of epochs\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        #each iteration of batch\n",
        "        for batch_start in range(0, len(x_train), batch_size):\n",
        "            batch_end = batch_start + batch_size\n",
        "            x_batch = x_train[batch_start:batch_end]\n",
        "            y_batch = y_train[batch_start:batch_end]\n",
        "\n",
        "            model.train_on_batch(x_batch, y_batch)\n",
        "\n",
        "        #calculating the loss and accuracy\n",
        "        loss, accuracy = model.evaluate(x_validation, y_validation, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        #calculating the error\n",
        "        error = 1 - accuracy\n",
        "        loss_values.append(loss)\n",
        "        error_values.append(error)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss:.4f} - Error: {error:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIywlNZ_QXkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b7d42d1c-f18a-4292-90ea-4fa17a0b962b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"362d0bf7-c1eb-49a7-b91d-bcfb5f524389\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"362d0bf7-c1eb-49a7-b91d-bcfb5f524389\")) {                    Plotly.newPlot(                        \"362d0bf7-c1eb-49a7-b91d-bcfb5f524389\",                        [{\"mode\":\"lines\",\"name\":\"Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250],\"y\":[0.12712818384170532,0.11213921755552292,0.10471256077289581,0.08845850825309753,0.0953725203871727,0.12065163254737854,0.08548212796449661,0.08440623432397842,0.09721764922142029,0.09846525639295578,0.0892408937215805,0.08545122295618057,0.10815871506929398,0.09292243421077728,0.10374060273170471,0.10604426264762878,0.08111665397882462,0.1030353382229805,0.1146429181098938,0.1179807037115097,0.11542621999979019,0.11493805795907974,0.13685236871242523,0.13716134428977966,0.12228814512491226,0.1123901829123497,0.12121113389730453,0.13980084657669067,0.11946806311607361,0.11797376722097397,0.11536227911710739,0.13746963441371918,0.12628228962421417,0.11315346509218216,0.12967975437641144,0.14365382492542267,0.12262465804815292,0.11648377776145935,0.13410082459449768,0.1414135843515396,0.1181647852063179,0.15475089848041534,0.11758077144622803,0.12037868797779083,0.16356249153614044,0.13907907903194427,0.13938677310943604,0.13612186908721924,0.11376778781414032,0.12204983085393906,0.15168246626853943,0.1276167333126068,0.13763327896595,0.12292222678661346,0.14543114602565765,0.1246429830789566,0.15729863941669464,0.14061041176319122,0.12760119140148163,0.12337949126958847,0.1270475685596466,0.1625913381576538,0.16386304795742035,0.13704250752925873,0.20058472454547882,0.15549877285957336,0.17237891256809235,0.15005283057689667,0.17065387964248657,0.18665224313735962,0.17435412108898163,0.1539866179227829,0.14293447136878967,0.14679428935050964,0.21112145483493805,0.186020165681839,0.17424246668815613,0.16467395424842834,0.14399808645248413,0.14124813675880432,0.1398785263299942,0.13963232934474945,0.13949163258075714,0.13942988216876984,0.13941563665866852,0.13944338262081146,0.13952821493148804,0.1396588385105133,0.13982535898685455,0.14004351198673248,0.14029280841350555,0.14058856666088104,0.14091849327087402,0.14129026234149933,0.14169394969940186,0.14213792979717255,0.14260593056678772,0.14309649169445038,0.14364048838615417,0.14421497285366058,0.1448403000831604,0.14551302790641785,0.14619950950145721,0.14691124856472015,0.14764803647994995,0.14841754734516144,0.14920349419116974,0.15000416338443756,0.1508122980594635,0.1516307294368744,0.15246279537677765,0.15330852568149567,0.15416543185710907,0.15501618385314941,0.15585525333881378,0.15666458010673523,0.15746356546878815,0.15823669731616974,0.15899492800235748,0.1597449779510498,0.1604880690574646,0.16114763915538788,0.16183491051197052,0.16244079172611237,0.16305392980575562,0.16366297006607056,0.16418205201625824,0.16468419134616852,0.16514839231967926,0.1656116396188736,0.1660577803850174,0.16645021736621857,0.16683036088943481,0.1671268343925476,0.16740502417087555,0.1676679253578186,0.16791574656963348,0.16815702617168427,0.16835348308086395,0.1685219258069992,0.16862912476062775,0.16871994733810425,0.1688559353351593,0.16895359754562378,0.16904263198375702,0.1690996289253235,0.16919025778770447,0.16926462948322296,0.16936282813549042,0.1694205105304718,0.16951921582221985,0.16958464682102203,0.16966238617897034,0.16973765194416046,0.16981680691242218,0.16986560821533203,0.16991087794303894,0.16994431614875793,0.16997362673282623,0.16999194025993347,0.17000430822372437,0.17002807557582855,0.17004068195819855,0.170060932636261,0.17007876932621002,0.17006701231002808,0.17006652057170868,0.1700689196586609,0.17005813121795654,0.170073464512825,0.1700516641139984,0.17003968358039856,0.17003986239433289,0.170037180185318,0.17002244293689728,0.17000888288021088,0.1700076162815094,0.1699904352426529,0.16998730599880219,0.1699918955564499,0.16999347507953644,0.16998516023159027,0.1700085550546646,0.16999764740467072,0.1699892282485962,0.1699635535478592,0.16997097432613373,0.1699599176645279,0.16994674503803253,0.16993075609207153,0.16992299258708954,0.1699153333902359,0.1698826402425766,0.16986678540706635,0.16985011100769043,0.16984228789806366,0.16982978582382202,0.16981974244117737,0.16982455551624298,0.16981443762779236,0.16978903114795685,0.16978719830513,0.16978144645690918,0.16976769268512726,0.1697724610567093,0.1697554737329483,0.16974453628063202,0.16973666846752167,0.1697096973657608,0.1697143167257309,0.16969658434391022,0.16969329118728638,0.1697026789188385,0.1696982979774475,0.16970320045948029,0.16967761516571045,0.1696881204843521,0.16969932615756989,0.1696801781654358,0.1696723848581314,0.1696917861700058,0.16966615617275238,0.16968560218811035,0.16968847811222076,0.1696821004152298,0.16966287791728973,0.16968433558940887,0.1696784794330597,0.1696809083223343,0.16967631876468658,0.16966946423053741,0.1696704775094986,0.16966645419597626,0.16965354979038239,0.16966433823108673,0.16966338455677032,0.16966094076633453,0.1696668565273285,0.1696552038192749,0.1696511059999466,0.16965126991271973,0.1696408987045288,0.16963793337345123,0.16964004933834076,0.16963601112365723,0.16962869465351105,0.1696331650018692,0.16962029039859772,0.1696263998746872,0.16961264610290527],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Cross-Entropy Loss\"},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('362d0bf7-c1eb-49a7-b91d-bcfb5f524389');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"2f4c1964-1049-426e-9d4f-52d835e16600\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2f4c1964-1049-426e-9d4f-52d835e16600\")) {                    Plotly.newPlot(                        \"2f4c1964-1049-426e-9d4f-52d835e16600\",                        [{\"mode\":\"lines\",\"name\":\"Classification Error\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250],\"y\":[0.03979998826980591,0.03579998016357422,0.03240001201629639,0.026600003242492676,0.024399995803833008,0.03240001201629639,0.02120000123977661,0.021000027656555176,0.020200014114379883,0.021000027656555176,0.018800020217895508,0.01940000057220459,0.025399982929229736,0.021000027656555176,0.021600008010864258,0.022000014781951904,0.017799973487854004,0.01940000057220459,0.020200014114379883,0.018999993801116943,0.01819998025894165,0.016799986362457275,0.022599995136260986,0.01940000057220459,0.01819998025894165,0.017199993133544922,0.018999993801116943,0.018000006675720215,0.017799973487854004,0.017000019550323486,0.016200006008148193,0.019599974155426025,0.01759999990463257,0.015799999237060547,0.017799973487854004,0.017199993133544922,0.01639997959136963,0.0153999924659729,0.017799973487854004,0.017199993133544922,0.014800012111663818,0.022000014781951904,0.01660001277923584,0.016200006008148193,0.021399974822998047,0.015799999237060547,0.015200018882751465,0.018599987030029297,0.013000011444091797,0.014800012111663818,0.01759999990463257,0.01639997959136963,0.014999985694885254,0.014999985694885254,0.015799999237060547,0.014400005340576172,0.01840001344680786,0.016200006008148193,0.014999985694885254,0.014400005340576172,0.013599991798400879,0.014599978923797607,0.015799999237060547,0.014599978923797607,0.019599974155426025,0.017799973487854004,0.017000019550323486,0.017199993133544922,0.016200006008148193,0.017199993133544922,0.018599987030029297,0.0153999924659729,0.014800012111663818,0.0153999924659729,0.02120000123977661,0.016200006008148193,0.017199993133544922,0.01639997959136963,0.013599991798400879,0.014199972152709961,0.013599991798400879,0.013199985027313232,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.01260000467300415,0.01260000467300415,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.012799978256225586,0.013000011444091797,0.013199985027313232,0.013199985027313232,0.013400018215179443,0.013400018215179443,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013400018215179443,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013199985027313232,0.013599991798400879,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013599991798400879,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013400018215179443,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797,0.013000011444091797],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Validation Classification Error\"},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Error\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2f4c1964-1049-426e-9d4f-52d835e16600');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create the loss plot\n",
        "loss_plot = go.Scatter(x=list(range(1, epochs+1)), y=loss_values, mode='lines', name='Loss')\n",
        "layout_loss = go.Layout(title='Cross-Entropy Loss', xaxis=dict(title='Epoch'), yaxis=dict(title='Loss'))\n",
        "fig_loss = go.Figure(data=[loss_plot], layout=layout_loss)\n",
        "fig_loss.show()\n",
        "\n",
        "# Create the classification error plot\n",
        "error_plot = go.Scatter(x=list(range(1, epochs+1)), y=error_values, mode='lines', name='Classification Error')\n",
        "layout_error = go.Layout(title='Validation Classification Error', xaxis=dict(title='Epoch'), yaxis=dict(title='Error'))\n",
        "fig_error = go.Figure(data=[error_plot], layout=layout_error)\n",
        "fig_error.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oea3sT8EqB0T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}